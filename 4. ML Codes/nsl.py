# -*- coding: utf-8 -*-
"""finalNSL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1deG8TVeppjxKaOSlRMxjn0eYBtaRe7_T
"""

import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation, Dropout

train_dir = '/content/drive/MyDrive/NslNsl/data/train'
test_dir = '/content/drive/MyDrive/NslNsl/data/test'

train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

index_to_folder = {0: "0", 1: "1", 2: "2", 3:"Ka", 4:"Kha", 5:"Ga", 6:"Gha", 7:"Yna", 8:"Chea", 9:"Cha", 10:"Ja", 11:"Ma", 12:"Ra", 13:"Yah", 14:"Bg"}

train_data = train_datagen.flow_from_directory(train_dir,
                              target_size=(300,300),
                              batch_size=32,
                              color_mode='grayscale',
                              class_mode='categorical')
test_data = test_datagen.flow_from_directory(test_dir,
                            target_size=(300,300),
                            batch_size=32,
                            color_mode='grayscale',
                            class_mode='categorical')

model = Sequential()
model.add(Conv2D(64,(3,3),input_shape=(300,300,1),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(128,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(256,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(128,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dense(128,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(32,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(15,activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history = model.fit(train_data, 
                    epochs=15,
                    steps_per_epoch=3000//train_data.batch_size,
                    validation_data=test_data, 
                    validation_steps=1000//test_data.batch_size)

model.save('/content/drive/MyDrive/finalNsl.h5')

import numpy as np
import matplotlib.pyplot as plt
import cv2

plt.plot(history.history['accuracy'],color='red',label='train')
plt.plot(history.history['val_accuracy'],color='blue',label='validaton')
plt.legend()
plt.show()

plt.plot(history.history['loss'],color='red',label='train')
plt.plot(history.history['val_loss'],color='blue',label='validation')
plt.legend()
plt.show()

# Import the necessary libraries
import os
import random
#from google.colab import drive

# Mount Google Drive
#drive.mount('/content/drive')

# Specify the folder in Google Drive where the images are stored
img_folder = '/content/drive/My Drive/predictDataCollect/'

# Get a list of all the image files in the folder
img_files = [f for f in os.listdir(img_folder) if f.endswith('.jpg') or f.endswith('.png')]

# Select a random image file from the list
rand_img = random.choice(img_files)

# Load the image file using matplotlib's imread function
img = plt.imread(os.path.join(img_folder, rand_img))

# Display the image using matplotlib's imshow function
plt.imshow(img)

# Show the plot
plt.show()

img.shape

img = img.reshape(1, 300, 300, 1)
img = img.astype('float32') / 255

img.shape

model.predict(img)

predicted_class_index = np.argmax(model.predict(img), axis=1)
predicted_class_index

predicted_class_index = int(predicted_class_index)
predicted_folder = index_to_folder[predicted_class_index]
print(f"The predicted folder is: {predicted_folder}")